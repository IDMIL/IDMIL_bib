@inproceedings{vieiraEverydayUseInternet2020,
  title = {Everyday {{Use}} of the {{Internet}} of {{Musical Things}}: {{Intersections}} with {{Ubiquitous Music}}},
  booktitle = {Proceedings of the {{Workshop}} on {{Ubiquitous Music}} 2020},
  author = {Vieira, Rômulo and Barthet, Mathieu and Schiavoni, Flávio Luiz},
  date = {2020-11},
  pages = {60--71},
  location = {{Porto Seguro, BA, Brasil}},
  doi = {10.5281/zenodo.4247759},
  url = {https://doi.org/10.5281/zenodo.4247759}
}

@inproceedings{rovanInstrumentalGesturalMapping1997,
  title = {Instrumental {Gestural} {Mapping} {Strategies} as {Expressivity} {Determinants} in {Computer} {Music} {Performance}},
  booktitle = {In {Proceedings} of {Kansei} - {The} {Technology} of {Emotion} {Workshop}},
  author = {Rovan, Joseph Butch and Wanderley, Marcelo M. and Dubnov, Shlomo and Depalle, Philippe},
  year = {1997},
  pages = {3--4}
}

@article{wessel_problems_2002,
  title = {Problems and {Prospects} for {Intimate} {Musical} {Control} of {Computers}},
  volume = {26},
  issn = {0148-9267},
  doi = {10.1162/014892602320582945},
  number = {3},
  urldate = {2020-11-02},
  journal = {Computer Music Journal},
  author = {Wessel, David and Wright, Matthew},
  month = sep,
  year = {2002},
  publisher = {MIT Press},
  pages = {11--22},
}

@phdthesis{wright_making_2017,
  type = {{PhD} {Thesis}},
  title = {Making {Hammers} with {Art}: {The} {Producer} of {House} and {Techno}},
  abstract = {My dissertation examines how producers of house and techno —two electronic dance music (EDM) genres— negotiate notions of artistry, professionalism, and authorship through their production practice. Producers of house and techno occupy a distinctive position where the success and recognition that their productions receive is dependent on their ability to create tracks (individual recordings) that facilitate DJ performances. As a result, producers simultaneously create tracks and tools, standalone pieces for dedicated listening that double as the functional materials for other musicians. In order to assert their professionalism and artistry producers adopt an experimental production practice centred on sound design. This experimental process requires a mastery of sound technologies and reflects the aesthetic legacies that define what it means to be a producer. A close study of creative practice provides a window into how individuals navigate complicated, and, at times, conflicting notions of what it means to be a professional artist. The first half of my dissertation is concerned with the context that informs production practice. Beginning with a discussion of the musical characteristics of house and techno, I provide a primer for those uninitiated in the intertwined histories and styles of these two important genres. This is followed by a discussion of German modernism, disco, and afro-futurism, which are identified as the chief aesthetics legacies that shape house and techno production. I then consider the material conditions and challenges producers face as working musicians. Drawing from in-studio fieldwork conducted in Berlin and Toronto, the latter half of my dissertation explores production practice through an examination of sound design that includes a discussion of synthesis, sampling, sequencing, mixing, and automation. I conclude that the producer’s experimental production practice, which relies on the utility of experimentation to yield artistic and functional tracks, is what allows them to assert their nuanced professional identity.},
  language = {English},
  author = {Wright, Edward},
  year = {2017},
  isbn = {978-0-355-53582-2},
  keywords = {0208:Music history, 0413:Music, Communication and the arts, Electronic dance music, House music, Music, Music history, Production practice, Recording practice, Techno music},
}

@inproceedings{wang_study_2020,
  address = {Singapore},
  title = {The {Study} of {Mapping} {Strategies} {Between} the {Excitators} of the {Single}-{Reed} {Woodwind} and the {Bowed} {String}},
  doi = {10.1007/978-981-15-2756-2_9},
  abstract = {Mapping is one of the most important components in digital musical instruments. There have been many works on “longitudinal” mapping strategies from the input device to the sound synthesizer. Such mapping can be considered longitudinal because the mapping direction is in line with the information transfer direction. However, less research focuses on “transversal” mappings among input devices or sound synthesizers. In this paper, a transversal mapping strategy is explored between the excitators of bowed strings and single-reed woodwinds which aims to allow more natural use of a given controller to play the sound of another family of instruments. A three-layer mapping structure, namely the playing layer, the mathematical layer, and the physical layer, is built. The mappings in different layers are generated based on the analogy of the mathematical models of two excitators in the mathematical layer. As a result, in the playing layer, the bowing force and the bowing speed of the string instrument are mapped to the lip force and the mouth pressure of a single-reed woodwind, respectively. In the physical layer, the string velocity and the friction force at the bowed point are mapped to the acoustic pressure and the volume velocity in the mouthpiece, respectively. Finally, a Yamaha WX5 wind controller is used to drive the digital waveguide string model. Two different mapping strategies between the lip force and the bowing force are tested and the results are discussed.},
  booktitle = {Proceedings of the 7th {Conference} on {Sound} and {Music} {Technology} ({CSMT})},
  publisher = {Springer Singapore},
  author = {Wang, Song and Wanderley, Marcelo M. and Scavone, Gary},
  editor = {Li, Haifeng and Li, Shengchen and Ma, Lin and Fang, Chunying and Zhu, Yidan},
  year = {2020},
  pages = {107--119},
}

@inproceedings{wang_webmapper_2019,
  title = {Webmapper: {A} {Tool} for {Visualizing} and {Manipulating} {Mappings} in {Digital} {Musical} {Instruments}},
  booktitle = {Proceedings of the 14th {International} {Conference} on {Computer} {Music} {Multidisciplinary} {Research} ({CMMR})},
  author = {Wang, Johnty and Malloch, Joseph and Sinclair, Stephen and Wilansky, Jonathan and Krajeski, Aaron and Wanderley, Marcelo M.},
  year = {2019},
}

@inproceedings{vigliensoni_soundcatcher_2010,
  title = {Soundcatcher: {Explorations} in {Audio}-{Looping} and {Time}-{Freezing} {Using} an {Open}-{Air} {Gestural} {Controller}},
  url = {http://hdl.handle.net/2027/spo.bbp2372.2010.020},
  booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
  author = {Vigliensoni, Gabriel and Wanderley, Marcelo M.},
  year = {2010},
  pages = {100--103},
}

@inproceedings{wang_scalability_2020,
  address = {Birmingham, UK},
  title = {The {Scalability} of {WiFi} for {Mobile} {Embedded} {Sensor} {Interfaces}},
  url = {https://www.nime.org/proceedings/2020/nime2020_paper14.pdf},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  publisher = {Birmingham City University},
  author = {Wang, Johnty and Meneses, Eduardo and Wanderley, Marcelo},
  editor = {Michon, Romain and Schroeder, Franziska},
  month = jul,
  year = {2020},
  note = {ISSN: 2220-4806},
  pages = {73--76},
}

@article{verfaille_mapping_2006,
  title = {Mapping {Strategies} for {Gestural} and {Adaptive} {Control} of {Digital} {Audio} {Effects}},
  volume = {35},
  doi = {10.1080/09298210600696881},
  abstract = {This paper discusses explicit mapping strategies for gestural and adaptive control of digital audio effects. We address the problem of defining what is the control and what is the effect. We then propose a mapping strategy derived from mapping techniques used in sound synthesis. The explicit mapping strategy we developed has two levels and two layers for each level: the first level is the adaptive control with a feature combination layer and a control signal conditioning layer; the second level is the gestural control layer. We give musical examples that illustrate the interest of this strategy.},
  journal = {Journal of New Music Research},
  author = {Verfaille, Vincent and Wanderley, Marcelo and Depalle, Philippe},
  month = mar,
  year = {2006},
  pages = {71--93},
}

@article{turchet2018co-design,
  title = {Co-design of a {Smart} {Cajón}},
  volume = {66},
  doi = {10.17743/jaes.2018.0007},
  number = {4},
  journal = {Journal of the Audio Engineering Society},
  author = {Turchet, Luca and McPherson, Andrew and Barthet, Mathieu},
  month = apr,
  year = {2018},
  pages = {220--230},
}

@article{turchet_internet_2018,
  title = {Internet of {Musical} {Things}: {Vision} and {Challenges}},
  volume = {6},
  doi = {10.1109/ACCESS.2018.2872625},
  journal = {IEEE Access},
  author = {Turchet, Luca and Fischione, Carlo and Essl, Georg and Keller, Damián and Barthet, Mathieu},
  year = {2018},
  pages = {61994--62017},
}

@misc{the_midi_manufacturers_association_specification_2015,
  title = {Specification for {MIDI} over {Bluetooth} {Low} {Energy} ({BLE}-{MIDI})},
  url = {https://www.midi.org/specifications/item/bluetooth-le-midi},
  author = {{The MIDI Manufacturers Association}},
  year = {2015},
}

@article{rodgers_process_2003,
  title = {On the {Process} and {Aesthetics} of {Sampling} in {Electronic} {Music} {Production}},
  volume = {8},
  doi = {10.1017/S1355771803000293},
  number = {3},
  journal = {Organised Sound},
  author = {Rodgers, Tara},
  year = {2003},
  publisher = {Cambridge University Press},
  pages = {313--320},
}

@article{reinecke_when_2009,
  title = {'{When} {I} {Count} to {Four}…': {James} {Brown}, {Kraftwerk}, and the {Practice} of {Musical} {Time} {Keeping} {Before} {Techno}},
  volume = {32},
  doi = {10.1080/03007760903251425},
  journal = {Popular Music and Society},
  author = {Reinecke, David},
  year = {2009},
  pages = {607--616},
}

@incollection{orlarey_faust_2009,
  title = {{FAUST}: {An} {Efficient} {Functional} {Approach} to {Dsp} {Programming}},
  url = {https://hal.archives-ouvertes.fr/hal-02159014},
  booktitle = {New {Computational} {Paradigms} for {Computer} {Music}},
  author = {Orlarey, Yann and Fober, Dominique and Letz, Stéphane},
  editor = {France, Editions Delatour},
  year = {2009},
  keywords = {compiler, dataflow, functional, processing, programming, real-time, signal},
  pages = {65--96},
}

@inproceedings{oliveira_da_silveira_xt_2018,
  address = {Blacksburg, Virginia, USA},
  title = {The {XT} {Synth}: {A} {New} {Controller} for {String} {Players}},
  isbn = {978-1-949373-99-8},
  doi = {10.5281/zenodo.1302673},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  publisher = {Virginia Tech},
  author = {Oliveira da Silveira, Gustavo},
  editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
  month = jun,
  year = {2018},
  note = {ISSN: 2220-4806},
  pages = {43--44},
}

@article{van_nort_mapping_2014,
  title = {Mapping {Control} {Structures} for {Sound} {Synthesis}: {Functional} and {Topological} {Perspectives}},
  volume = {38},
  doi = {10.1162/COMJ_a_00253},
  journal = {Computer Music Journal},
  author = {van Nort, Doug and Wanderley, Marcelo M. and Depalle, Philippe},
  year = {2014},
  pages = {6--22},
}

@inproceedings{nieva_t-stick_2018,
  address = {Blacksburg, Virginia, USA},
  title = {The {T}-{Stick}: {Maintaining} a 12 {Year}-{Old} {Digital} {Musical} {Instrument}},
  isbn = {978-1-949373-99-8},
  url = {http://www.nime.org/proceedings/2018/nime2018_paper0042.pdf},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  publisher = {Virginia Tech},
  author = {Nieva, Alex and Wang, Johnty and Malloch, Joseph and Wanderley, Marcelo},
  editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
  month = jun,
  year = {2018},
  note = {ISSN: 2220-4806},
  pages = {198--199},
}

@inproceedings{barbosa_exploring_2017,
  address = {Copenhagen, Denmark},
  title = {Exploring playfulness in {NIME} design: the case of live looping tools},
  doi = {10.5281/zenodo.1176181},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  publisher = {Aalborg University Copenhagen},
  author = {Barbosa, Jeronimo and Wanderley, Marcelo M. and Huot, Stéphane},
  year = {2017},
  pages = {87--92},
}

@inproceedings{mitchell_soundgrasp_2011,
  address = {Oslo, Norway},
  title = {Soundgrasp: {A} {Gestural} {Interface} for the {Performance} of {Live} {Music}},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  author = {Mitchell, Thomas and Heap, Imogen},
  year = {2011},
  keywords = {Data Glove, Gestural Music, Imogen Heap, Live Music Composition, Looping, Music Controller, Neural Network},
  pages = {465--468},
  doi = {10.5281/zenodo.1178111}
}

@misc{bastl_instruments_midilooper_2020,
  title = {Midilooper},
  url = {https://bastl-instruments.com/instruments/midilooper},
  abstract = {Bastl instruments (est.2013) is a community driven company with a main focus on development and production of electronic musical instruments - from portable sound boxes, studio instruments or utilities to fully featured eurorack modular synthesizer systems. We do all sorts of community projects, such as organizing music related events, coffee roasting, record label, educational content, workshops or even a clothing production. We are based in Brno, Czech republic.},
  language = {en},
  urldate = {2020-11-19},
  author = {Bastl Instruments},
  year = {2020},
}

@misc{the_midi_manufacturers_association_midi_2018,
  title = {{MIDI} {Polyphonic} {Expression} {Version} 1.0},
  url = {https://www.midi.org/articles-old/midi-polyphonic-expression-mpe},
  author = {{The MIDI Manufacturers Association}},
  year = {2018},
}

@misc{michael_peters_michael_1996,
  title = {Michael {Peters}: {The} {Birth} of {Loop} (1996-)},
  url = {http://www.livelooping.org/history_concepts/theory/the-birth-of-loop/},
  language = {en-US},
  urldate = {2020-09-28},
  author = {Michael Peters},
  year = {1996},
}

@inproceedings{malloch_towards_2006,
  title = {Towards a {New} {Conceptual} {Framework} for {Digital} {Musical} {Instruments}},
  booktitle = {Proceedings of the 9th {International} {Conference} on {Digital} {Audio} {Effects} ({DAFx}-06)},
  author = {Malloch, Joseph and Birnbaum, David and Sinyor, Elliot and Wanderley, Marcelo M.},
  year = {2006},
}

@inproceedings{malloch_t-stick_2007,
  address = {New York City, NY, United States},
  title = {The {T}-{Stick}: {From} {Musical} {Interface} to {Musical} {Instrument}},
  doi = {10.5281/zenodo.1177175},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  author = {Malloch, Joseph and Wanderley, Marcelo M.},
  year = {2007},
  keywords = {digital musical instrument, families of instruments, gestural controller},
  pages = {66--69},
}

@article{malloch_distributed_2015,
  title = {Distributed {Tools} for {Interactive} {Design} of {Heterogeneous} {Signal} {Networks}},
  volume = {74},
  issn = {1573-7721},
  doi = {10.1007/s11042-014-1878-5},
  abstract = {We introduce libmapper, an open source, cross-platform software library for flexibly connecting disparate interactive media control systems at run-time. This library implements a minimal, openly-documented protocol meant to replace and improve on existing schemes for connecting digital musical instruments and other interactive systems, bringing clarified, strong semantics to system messaging and description. We use automated discovery and message translation instead of imposed system-representation standards to approach “plug-and-play” usability without sacrificing design flexibility. System modularity is encouraged, and data are transported between peers without centralized servers.},
  number = {15},
  journal = {Multimedia Tools and Applications},
  author = {Malloch, Joseph and Sinclair, Stephen and Wanderley, Marcelo M.},
  month = aug,
  year = {2015},
  pages = {5683--5707},
}

@article{madgwick_simple_2015,
  title = {Simple {Synchronisation} for {Open} {Sound} {Control}},
  url = {https://uwe-repository.worktribe.com/output/829212},
  abstract = {Clock synchronisation is a mature and important aspect of distributed computing systems. Despite the importance of accurate timing in music, there are relatively few widely applicable synchronisation solutions available to computer music practitioners. In this paper we present a simple OSC-based synchronisation method for wired and wireless applications, which is designed to be easy to apply and is shown to offer accuracy appropriate for fine-grained music applications. The proposed solution relies on a single master sending a synchronisation message to all slaves. Empirical studies with a heterogeneous network of 17 Wi-Fi slaves and 5 Ethernet slaves demonstrate that each homogeneous group is able to achieve a relative synchronisation accuracy of 166 us and 100 us respectively, offset from the master time by their respective network latencies. An acoustic localisation system is implemented to demonstrate an application that requires both accurate synchronisation and benefits from wireless connectivity. The system is shown to precisely locate a sound source with a standard deviation of 1.8 mm.},
  language = {en},
  urldate = {2020-11-23},
  author = {Madgwick, Sebastian O. H. and Mitchell, Thomas J. and Barreto, Carlos and Freed, Adrian},
  month = sep,
  year = {2015},
}

@article{m_m_wanderley_gestural_2004,
  title = {Gestural {Control} of {Sound} {Synthesis}},
  volume = {92},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2004.825882},
  abstract = {This paper provides a review of gestural control of sound synthesis in the context of the design and evaluation of digital musical instruments. It discusses research in various areas related to this field and equally focuses on four main topics: analysis of music performers' gestures, gestural capture technologies, real-time sound synthesis methods, and strategies for mapping gesture variables to sound synthesis input parameters. Finally, this approach is illustrated by presenting an application of this research to the control of digital audio effects.},
  number = {4},
  journal = {Proceedings of the IEEE},
  author = {Wanderley, Marcelo M. and  Depalle, Philippe},
  month = apr,
  year = {2004},
  keywords = {Application software, Automatic control, Control system synthesis, Haptic interfaces, Human computer interaction, Instruments, Keyboards, Music, Performance analysis, Signal synthesis, audio systems, digital audio effects, digital musical instruments, electronic music, gestural capture technologies, gestural control, gesture recognition, gesture variables mapping, music, music performers gestures analysis, musical instruments, real time sound synthesis, signal synthesis, user interfaces},
  pages = {632--644},
}

@inproceedings{kirkegaard_torquetuner_2020,
  address = {Birmingham, UK},
  title = {{TorqueTuner}: {A} {Self} {Contained} {Module} for {Designing} {Rotary} {Haptic} {Force} {Feedback} for {Digital} {Musical} {Instruments}},
  url = {https://www.nime.org/proceedings/2020/nime2020_paper52.pdf},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  publisher = {Birmingham City University},
  author = {Kirkegaard, Mathias and Bredholt, Mathias and Frisson, Christian and Wanderley, Marcelo},
  editor = {Michon, Romain and Schroeder, Franziska},
  month = jul,
  year = {2020},
  note = {ISSN: 2220-4806
tex.presentation-video: https://youtu.be/V8WDMbuX9QA},
  pages = {273--278},
}

@inproceedings{kirkegaard_intermediate_2020,
  address = {Cham},
  title = {An {Intermediate} {Mapping} {Layer} for {Interactive} {Sequencing}},
  isbn = {978-3-030-50017-7},
  abstract = {The definition of mapping strategies between input devices and sound generating algorithms is an essential process in computer music. Traditionally, mapping has been considered in the context of digital musical instruments where the control of low level sound features (note articulation, timbre) is the goal. This paper describes the motivation, implementation and example application of an intermediate mapping layer for interactive sequencing. Building upon the mapping literature, we expand it by exploring the control of predefined musical sequences, focusing on the ability to make spontaneous musical decisions, creative exploration by browsing, and easy mapping between devices. It involves a parameterization of rhythm, melody, and harmony along with collaborative mappings in both libmapper and Ableton Link.},
  booktitle = {Human {Interface} and the {Management} of {Information}. {Interacting} with {Information}},
  publisher = {Springer International Publishing},
  author = {Kirkegaard, Mathias and Bredholt, Mathias and Wanderley, Marcelo M.},
  editor = {Yamamoto, Sakae and Mori, Hirohiko},
  year = {2020},
  pages = {447--456},
}

@inproceedings{hunt_importance_2002,
  address = {Dublin, Ireland},
  title = {The {Importance} of {Parameter} {Mapping} in {Electronic} {Instrument} {Design}},
  doi = {10.5281/zenodo.1176424},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  author = {Hunt, Andy D. and Wanderley, Marcelo M. and Paradis, Matthew},
  month = may,
  year = {2002},
  keywords = {electronic musical instruments, human-computer interaction, mapping strategies},
  pages = {88--93},
}

@article{hunt_mapping_2002,
  title = {Mapping {Performer} {Parameters} to {Synthesis} {Engines}},
  volume = {7},
  doi = {10.1017/S1355771802002030},
  number = {2},
  journal = {Organised Sound},
  author = {Hunt, Andy and Wanderley, Marcelo M.},
  year = {2002},
  publisher = {Cambridge University Press},
  pages = {97--108},
}

@inproceedings{hattwick_vibropixels_2017,
  address = {Cham},
  title = {The {Vibropixels}: {A} {Scalable} {Wireless} {Tactile} {Display} {System}},
  isbn = {978-3-319-58521-5},
  abstract = {This paper presents a wearable, wireless tactile display system which consists of individually controllable vibrotactile actuator devices, called Vibropixels. The design of the system is easily scalable and reconfigurable, allowing for implementation in a variety of applications. The system removes any limit on the number of actuator devices by avoiding both hand-shaking and packet acknowledgement functionality. The number of control messages required is minimized through the use of a exible two-part addressing scheme as well as functions allowing for the generation of multiple actuator envelopes on the devices. Created within an interdisciplinary art-science research project, 145 Vibropixels were utilized in the premier of the artistic installation Haptic Field. Recognizing that the artistic creation process often involves utilizing systems beyond their intended application, we designed our system to allow our collaborators to interact with and potentially modify the system on a hardware, firmware, or software level. Through interviews with our collaborators, we evaluated our system's ability to support the artistic creation process in light of Shneiderman's principles for creativity support tools. While our collaborators mostly used and modified the highest level software tools provided to them, we argue that supporting lower level modifications may still be useful depending upon available time and the knowledge of the user.},
  booktitle = {Human {Interface} and the {Management} of {Information}: {Information}, {Knowledge} and {Interaction} {Design}},
  publisher = {Springer International Publishing},
  author = {Hattwick, Ian and Franco, Ivan and Wanderley, Marcelo M.},
  editor = {Yamamoto, Sakae},
  year = {2017},
  pages = {517--528},
  doi = {10.1007/978-3-319-58521-5_40}
}

@book{grigorik_high_2013,
  title = {High {Performance} {Browser} {Networking}: {What} {Every} {Web} {Developer} {Should} {Know} {About} {Networking} and {Web} {Performance}},
  isbn = {978-1-4493-4474-0},
  shorttitle = {High {Performance} {Browser} {Networking}},
  abstract = {How prepared are you to build fast and efficient web applications? This eloquent book provides what every web developer should know about the network, from fundamental limitations that affect performance to major innovations for building even more powerful browser applications—including HTTP 2.0 and XHR improvements, Server-Sent Events (SSE), WebSocket, and WebRTC.Author Ilya Grigorik, a web performance engineer at Google, demonstrates performance optimization best practices for TCP, UDP, and TLS protocols, and explains unique wireless and mobile network optimization requirements. You’ll then dive into performance characteristics of technologies such as HTTP 2.0, client-side network scripting with XHR, real-time streaming with SSE and WebSocket, and P2P communication with WebRTC.Deliver superlative TCP, UDP, and TLS performanceSpeed up network performance over 3G/4G mobile networksDevelop fast and energy-efficient mobile applicationsAddress bottlenecks in HTTP 1.x and other browser protocolsPlan for and deliver the best HTTP 2.0 performanceEnable efficient real-time streaming in the browserCreate efficient peer-to-peer videoconferencing and low-latency applications with real-time WebRTC transports},
  language = {en},
  publisher = {"O'Reilly Media, Inc."},
  author = {Grigorik, Ilya},
  month = sep,
  year = {2013},
  keywords = {Computers / Networking / General, Computers / Web / Browsers, Computers / Web / Web Programming},
}

@inproceedings{goltz_ableton_2018,
  title = {Ableton {Link}: {A} {Technology} to {Synchronize} {Music} {Software}},
  url = {http://dx.doi.org/10.14279/depositonce-7046},
  booktitle = {Proceedings of the {Linux} {Audio} {Conference}},
  author = {Goltz, Florian},
  year = {2018},
  pages = {39--42},
}

@article{fels_mapping_2002,
  title = {Mapping {Transparency} {Through} {Metaphor}: {Towards} {More} {Expressive} {Musical} {Instruments}},
  volume = {7},
  issn = {1355-7718},
  url = {https://www.cambridge.org/core/article/mapping-transparency-through-metaphor-towards-more-expressive-musical-instruments/6A0DCDB0E31E7C01AEEA29427EA7F42A},
  doi = {10.1017/S1355771802002042},
  abstract = {We define a two-axis transparency framework that can be used as a predictor of the expressivity of a musical device. One axis is the player's transparency scale, while the other is the audience's transparency scale. Through consideration of both traditional instruments and new technology-driven interfaces, we explore the role that metaphor plays in developing expressive devices. Metaphor depends on a literature, which forms the basis for making transparent device mappings. We examine four examples of systems that use metaphor: Iamascope, Sound Sculpting, MetaMuse and Glove-TalkII; and discuss implications on transparency and expressivity. We believe this theory provides a framework for design and evaluation of new human–machine and human–human interactions, including musical instruments.},
  number = {2},
  journal = {Organised Sound},
  author = {Fels, Sidney and Gadd, Ashley and Mulder, Axel},
  year = {2002},
  publisher = {Cambridge University Press},
  pages = {109--126},
}

@misc{olimex_esp32-poe_nodate,
  title = {{ESP32}-{POE} - {Open} {Source} {Hardware} {Board}},
  url = {https://www.olimex.com/Products/IoT/ESP32/ESP32-POE/open-source-hardware},
  abstract = {ESP32-POE IoT development board with 100Mb Ethernet, Power over Ethernet, WiFi, BLE, programmer},
  language = {en},
  urldate = {2020-11-26},
  journal = {Olimex},
  author = {Olimex},
}

@misc{espressif_systems_esp32-lyrat_2020,
  title = {{ESP32}-{Lyrat} {V4}.3 {Getting} {Started} {Guide} — {Audio} {Development} {Framework} {Documentation}},
  url = {https://docs.espressif.com/projects/esp-adf/en/latest/get-started/get-started-esp32-lyrat.html},
  urldate = {2020-11-02},
  author = {Espressif},
  year = {2020},
}

@misc{espressif_systems_esp32_2020,
  title = {{ESP32} {Modules} and {Boards} - {ESP32} - — {ESP}-{IDF} {Programming} {Guide} {Latest} {Documentation}},
  url = {https://docs.espressif.com/projects/esp-idf/en/latest/esp32/hw-reference/modules-and-boards.html#esp32-wrover-series},
  urldate = {2020-11-11},
  author = {Espressif},
  year = {2020},
}

@inproceedings{michon:hal-02988312,
  TITLE = {{A Faust Architecture for the ESP32 Microcontroller}},
  AUTHOR = {Michon, Romain and Overholt, Daniel and Letz, Stephane and Orlarey, Yann and Fober, Dominique and Dumitrascu, Catinca},
  URL = {https://hal.archives-ouvertes.fr/hal-02988312},
  BOOKTITLE = {{Sound and Music Computing Conference (SMC-20)}},
  ADDRESS = {Turin, Italy},
  YEAR = {2020},
  MONTH = Jun,
  PDF = {https://hal.archives-ouvertes.fr/hal-02988312/file/smc20_faust_esp32.pdf},
  HAL_ID = {hal-02988312},
  HAL_VERSION = {v1},
}

@inproceedings{celerier_ossia_2015,
  address = {Paris, France},
  title = {{OSSIA}: {Towards} a {Unified} {Interface} for {Scoring} {Time} and {Interaction}},
  isbn = {978-2-9552905-0-7},
  booktitle = {Proceedings of the {First} {International} {Conference} on {Technologies} for {Music} {Notation} and {Representation} – {Tenor}'15},
  author = {Celerier, Jean-Michaël and Baltazar, Pascal and Bossut, Clément and Vuaille, Nicolas and Couturier, Jean-Michel and Desainte-Catherine, Myriam},
  editor = {Battier, Marc and Bresson, Jean and Couprie, Pierre and Davy-Rigaux, Cécile and Fober, Dominique and Geslin, Yann and Genevois, Hugues and Picard, François and Tacaille, Alice},
  year = {2015},
  pages = {81--90},
}

@article{cascone_aesthetics_2000,
  title = {The {Aesthetics} of {Failure}: "{Post}-{Digital}" {Tendencies} in {Contemporary} {Computer} {Music}},
  volume = {24},
  doi = {10.1162/014892600559489},
  number = {4},
  journal = {Computer Music Journal},
  author = {Cascone, Kim},
  year = {2000},
  pages = {12--18},
}

@book{butler_playing_2014,
  address = {New York},
  edition = {1st edition},
  title = {Playing with {Something} {That} {Runs}: {Technology}, {Improvisation}, and {Composition} in {DJ} and {Laptop} {Performance}},
  isbn = {978-0-19-539362-0},
  shorttitle = {Playing with {Something} {That} {Runs}},
  abstract = {Winner of the 2015 PMIG Outstanding Publication Award from the Society of Music TheoryThe DJs and laptop performers of electronic dance music use preexistent elements such as vinyl records and digital samples to create fluid, dynamic performances. These performances are also largely improvised, evolving in response to the demands of a particular situation through interaction with a dancing audience. Within performance, musicians make numerous spontaneous decisions about variables such as which sounds they will play, when they will play them, and how they will be combined with other sounds. Yet the elements that constitute these improvisations are also fixed in certain fundamental ways: performances are fashioned from patterns or tracks recorded beforehand, and in the case of DJ sets, these elements are also physical objects (vinyl records).In Playing with Something That Runs, author Mark J. Butler explores these improvised performances, revealing the ways in which musicians utilize seemingly invariable prerecorded elements to create novel improvisations. Based on extensive interviews with musicians in their studios, as well as in-depth studies of particular mediums of performance, including both DJ and laptop sets, Butler illustrates the ways in which technologies, both material and musical, are used in performance and improvisation in order to make these transformations possible. An illuminating look at the world of popular electronic-music performance, Playing with Something that Runs is an indispensable resource for electronic dance musicians and fans as well as scholars and students of popular music.},
  language = {English},
  publisher = {Oxford University Press},
  author = {Butler, Mark J.},
  month = jul,
  year = {2014},
}

@article{brower_memory_1993,
  title = {Memory and the {Perception} of {Rhythm}},
  volume = {15},
  issn = {0195-6167},
  url = {http://www.jstor.org/stable/745907},
  doi = {10.2307/745907},
  abstract = {Consideration of the roles of echoic, short-term, and long-term memory in rhythmic perception yields a three-fold division of the rhythmic hierarchy into foreground, middleground, and background. It appears that at middleground levels meter provides a quantitative basis for rhythmic perception, while at foreground and background levels rhythms are perceived more qualitatively. It also appears that at lower middleground levels meter is perceived using an entrainment strategy, while at higher middleground levels perception is based on a counting strategy. Evidence for these perceptual differences is found in the kinds of metric irregularities introduced at each level, with lower levels being characterized by syncopations and higher levels by expansions and contractions.},
  number = {1},
  urldate = {2020-11-26},
  journal = {Music Theory Spectrum},
  author = {Brower, Candace},
  year = {1993},
  publisher = {Oxford University Press, Society for Music Theory},
  pages = {19--35},
}

@inproceedings{berthaut_drile_2010,
  address = {Sydney, Australia},
  title = {{DRILE}: {An} {Immersive} {Environment} for {Hierarchical} {Live}-{Looping}},
  doi = {10.5281/zenodo.1177721},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  author = {Berthaut, Florent and Desainte-Catherine, Myriam and Hachet, Martin},
  year = {2010},
  keywords = {3D interac- tion, Drile, hierarchical live-looping, immersive instrument},
  pages = {192--197},
}

@misc{christopher_m_kohlhoff_asio_2020,
  title = {Asio {C}++ {Library}},
  url = {http://think-async.com/Asio/},
  urldate = {2020-05-19},
  author = {Christopher M. Kohlhoff},
  year = {2020},
}


@online{ableton_music_2020,
  title = {Music {{Production}} with {{Live}} and {{Push}} | {{Ableton}}},
  date = {2020},
  url = {https://www.ableton.com/en/},
  urldate = {2020-11-17},
  abstract = {Ableton makes Push and Live, hardware and software for music production, creation and performance. Ableton´s products are made to inspire creative music-making.},
  author = {Ableton},
}


@misc{noauthor_library_2020,
  title = {Library {Specification} - {Arduino} {CLI}},
  url = {https://arduino.github.io/arduino-cli/library-specification/},
  urldate = {2020-05-20},
  year = {2020},
}

@misc{noauthor_freertos_nodate,
  title = {{FreeRTOS} - {Market} leading {RTOS} ({Real} {Time} {Operating} {System}) for embedded systems with {Internet} of {Things} extensions},
  url = {https://www.freertos.org/},
  abstract = {FreeRTOS is a market-leading real-time operating system (RTOS) for microcontrollers and small microprocessors. Distributed freely under the MIT open source license, FreeRTOS includes a kernel and a growing set of IoT libraries suitable for use across all industry sectors. FreeRTOS is built with an emphasis on reliability and ease of use.},
  language = {en-US},
  urldate = {2020-12-01},
 }

@misc{noauthor_esp32-s2_nodate,
  title = {{ESP32}-{S2} {Wi}-{Fi} {MCU}},
  url = {https://www.espressif.com/en/products/socs/esp32-s2},
  urldate = {2020-12-01},
  author = {Espressif}
}

@misc{noauthor_mumt620-t-stick_2019,
  title = {{MUMT620}-t-stick},
  url = {http://www-new.idmil.org/education/mumt620-t-stick/},
  abstract = {Building a Sopranino T-Stick Bill of Materials Sensors 1 Capsense breakout board (CY8CMBR3116) 1 IMU breakout board LSM9DS1 1 FSR 1 Piezo Electronics 1 microcontroller Lolin D32 Pro 0.1uF capacitor…},
  language = {en-US},
  urldate = {2020-11-02},
  month = feb,
  year = {2019},
  author = {Nieva, Alex}
}

@misc{david_bawiec_what_2018,
  title = {What is mix automation? {Everything} you've been too afraid to ask},
  shorttitle = {What is mix automation?},
  url = {https://www.izotope.com/en/learn/what-is-mix-automation.html},
  abstract = {Have questions about mix automation in a DAW? We have answers. Learn what  automation is, when to use it, the types of automation modes, and more.},
  language = {en},
  urldate = {2020-10-20},
  journal = {iZotope},
  author = {David Bawiec},
  year = {2018},
}

@article{dannenberg_interpretation_nodate,
  title = {The interpretation of {MIDI} velocity},
  abstract = {The MIDI standard does not specify how MIDI key velocity is to be interpreted. Of course, individual synthetic instruments respond differently, but one would expect that on average, instruments will respond about the same. This study aims to determine empirically how hardware and software MIDI synthesizers translate velocity to peak RMS amplitude. Analysis shows synthesizers roughly follow an xsquared rather than exponential mapping. Given a desired dynamic range (from velocity 1 to 127), a square-law mapping from velocity to RMS is uniquely determined, making dynamic range a convenient way to summarize behavior. Surprisingly, computed values of dynamic range for commercial synthesizers vary by more than 60dB.},
  language = {en},
  author = {Dannenberg, Roger B},
  pages = {4},
}

@article{esqueda_virtual_2017,
  title = {Virtual analog buchla 259 wavefolder},
  abstract = {An antialiased digital model of the wavefolding circuit inside the Buchla 259 Complex Waveform Generator is presented. Wavefolding is a type of nonlinear waveshaping used to generate complex harmonically-rich sounds from simple periodic waveforms. Unlike other analog wavefolder designs, Buchla’s design features ﬁve op-amp-based folding stages arranged in parallel alongside a direct signal path. The nonlinear behavior of the system is accurately modeled in the digital domain using memoryless mappings of the input–output voltage relationships inside the circuit. We pay special attention to suppressing the aliasing introduced by the nonlinear frequency-expanding behavior of the wavefolder. For this, we propose using the bandlimited ramp (BLAMP) method with eight times oversampling. Results obtained are validated against SPICE simulations and a highly oversampled digital model. The proposed virtual analog wavefolder retains the salient features of the original circuit and is applicable to digital sound synthesis.},
  language = {en},
  author = {Esqueda, Fabián and Pöntynen, Henri and Välimäki, Vesa and Parker, Julian D},
  year = {2017},
  pages = {8},
}

@book{torso_electronics_torso_nodate,
  title = {Torso electronics homepage},
  url = {https://www.torsoelectronics.com},
  author = {Torso Electronics},
}

@misc{zaccagnini_non-linear_nodate,
  title = {Non-linear sequencing},
  url = {/paper/Non-linear-Sequencing-Zaccagnini/e65bf3d6e2dad5b9b2bc340ef8b220b0c17e93eb},
  abstract = {Since the early developments of the MIDI protocol, electronic musicians have been  making use of sequencers and keyboards to playback MIDI data. In its most basic form,  a sequencer triggers events by reading through a list of performance information, such  as pitch, duration, and velocity. While a keyboard allows for direct human-machine  interaction, a sequencer presupposes a mediated interaction in which the sequence is  first written and stored and subsequently played back by the sequencer. The sequencer  has become a ubiquitous tool for music composition and can be found in virtually any  Digital Audio Workstation (DAW) (Cuadrado, 2015). Furthermore, the sequencer has  1},
  language = {en},
  urldate = {2020-11-26},
  author = {Zaccagnini, Michele},
}

@inproceedings{wright_opensoundcontrol_1997,
  title = {{OpenSoundControl}: a new protocol for communicating with sound synthesizers},
  booktitle = {{ICMC}},
  author = {Wright, Matthew and Freed, Adrian},
  year = {1997},
}

@inproceedings{hinrichsen_post-dmi_2016,
  address = {Norrkoping, Sweden},
  title = {Post-{DMI} musical instruments},
  isbn = {978-1-4503-4822-5},
  url = {http://dl.acm.org/citation.cfm?doid=2986416.2986440},
  doi = {10.1145/2986416.2986440},
  abstract = {What are the particularities of developing contemporary instruments? This text points out how the authors observed both a focal shift and persisting elements in the design of contemporary digital musical instruments (DMI’s). Based on observations around selected instrument prototypes that were developed by students as well as the authors, four constituent aspects of the development process of hybrid instruments emerged: corporeality — the role of the body, materiality — the role of material, sound — the instrument’s sonic appearance, and control — its behaviour.},
  language = {en},
  urldate = {2020-10-29},
  booktitle = {Proceedings of the {Audio} {Mostly} 2016 on - {AM} '16},
  publisher = {ACM Press},
  author = {Hinrichsen, Amelie and Bovermann, Till},
  year = {2016},
  pages = {124--131},
}

@misc{noauthor_midi_nodate,
  title = {{MIDI} looper {LIVE} – choralcode},
  url = {https://choralcode.uk/midi-looper-live/},
  language = {en-GB},
  urldate = {2020-10-20},
}

@misc{noauthor_midiphy_nodate,
  title = {midiphy {LoopA} v2 - {MIDI} looper - requantizing sequencer - {MIDI} {DIY}},
  url = {https://www.midiphy.com/en/loopa-v2/},
  urldate = {2020-10-20},
}

@misc{noauthor_oscseq_nodate,
  title = {{OSCseq} - gallery},
  url = {http://oscseq.com/gallery/},
  urldate = {2020-05-24},
}

@misc{espressif_systems_miscellaneous_2020,
  title = {Miscellaneous system {APIs} - {ESP32} - — {ESP}-{IDF} programming guide latest documentation},
  url = {https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/system/system.html#_CPPv410esp_randomv},
  urldate = {2020-05-19},
  author = {Espressif},
  year = {2020},
}

@misc{fosterpaul_our_nodate,
  title = {Our planet: jungles worksheet},
  shorttitle = {Our planet},
  url = {https://www.tes.com/teaching-resource/our-planet-jungles-worksheet-12137444},
  abstract = {A worksheet for students to do whilst watching the Our Planet documentary Jungle episode (season 1, episode 3). The episode is currently available on Netfl...},
  language = {en},
  urldate = {2020-05-19},
  journal = {TES Resources},
  author = {fosterpaul},
  note = {Library Catalog: www.tes.com},
}

@book{gurevich_jamspace_2006,
  title = {{JamSpace}: designing a collaborative networked music space for novices.},
  shorttitle = {{JamSpace}},
  abstract = {An interactive music environment to support real-time jamming by novices and amateur musicians over a network is described. JamSpace takes advantage of the low latency and connectivity of a local area network (LAN) to allow real-time rhythmic collaboration from isolated locations. Several demonstrated needs that motivate the design are discussed in detail. These include technologically-mediated ways of restoring casual social interactions to the domain of music creation and the preservation of anonymity and privacy for amateur musicians in a group setting. JamSpace's design addresses these needs with a novel hardware and software interface incorporating listening, private rehearsal, mixing, looping tracks and real-time jamming. User-configurable levels of interactivity are analyzed in terms of social spaces.},
  author = {Gurevich, Michael},
  month = jan,
  year = {2006},
  note = {Pages: 123},
}

@book{rasmussen_information_1986,
  title = {Information processing and human-machine interaction: an approach to cognitive engineering},
  isbn = {978-0-444-00987-6},
  shorttitle = {Information processing and human-machine interaction},
  language = {en},
  publisher = {North-Holland},
  author = {Rasmussen, Jens},
  year = {1986},
  note = {Google-Books-ID: rKUoAQAAMAAJ},
}

@misc{noauthor_lfo_nodate,
  title = {{LFO} tool: powerful {LFO} shaping},
  url = {https://xferrecords.com/products/lfo-tool},
  urldate = {2020-11-17},
}

@article{cascone_grain_2003,
  title = {Grain, sequence, system: three levels of reception in the performance of laptop music},
  volume = {22},
  issn = {0749-4467},
  shorttitle = {Grain, sequence, system},
  url = {https://www.academia.edu/1764778/Grain_sequence_system_Three_levels_of_reception_in_the_performance_of_laptop_music},
  abstract = {Grain, sequence, system: Three levels of reception in the performance of laptop music},
  language = {en},
  number = {4},
  urldate = {2020-11-17},
  journal = {Contemporary Music Review},
  author = {Cascone, Kim},
  year = {2003},
  pages = {101--104},
}

@misc{noauthor_juce_nodate,
  title = {{JUCE}: class index},
  url = {https://docs.juce.com/master/index.html},
  urldate = {2020-11-02},
}

@misc{espressif_systems_high_2020,
  title = {High resolution timer - {ESP32} - — {ESP}-{IDF} programming guide latest documentation},
  url = {https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/system/esp_timer.html},
  urldate = {2020-05-19},
  author = {Espressif},
  year = {2020},
}

@misc{harris_liblo_2004,
  title = {liblo: lightweight {OSC} implementation},
  url = {http://liblo.sourceforge.net/},
  urldate = {2020-05-05},
  author = {Harris, Steve and Sinclair, Stephen},
  year = {2004},
}

@misc{laboratories_giada_nodate,
  title = {Giada - your hardcore loop machine},
  url = {https://www.giadamusic.com},
  abstract = {Giada is an open source, minimalistic and hardcore music production tool. Designed for DJs, live performers and electronic musicians.},
  language = {en},
  urldate = {2020-04-18},
  author = {Laboratories, Monocasual},
  note = {Library Catalog: www.giadamusic.com},
}

@book{jorda_fmol_2001,
  title = {{FMOL}: a system for collaborative music composition over the web.},
  shorttitle = {{FMOL}},
  abstract = {In this paper the authors propose a new architecture and new features for collaborative music composition. These design principles have been applied, without any loss of generality, to a system that has already been extensively tested on-line for the last three years, and which has allowed composers from around the world to participate in the collective creation of two important theatrical scores. They can constitute the basis for new approaches for collective composition on the Internet.},
  author = {Jordà, Sergi and Wüst, Otto},
  month = jan,
  year = {2001},
  note = {Pages: 542},
}

@article{barbosa_displaced_2003,
  title = {Displaced soundscapes: a survey of network systems for music and sonic art creation},
  volume = {13},
  shorttitle = {Displaced soundscapes},
  doi = {10.1162/096112104322750791},
  abstract = {The introduction of various collaborative tools, made possible by the expansion of computer network systems and communications technology, has led to new methods of musical composition and improvisation. The author describes a number of recent music and sound art projects involving the use of network systems that enable geographically displaced creators to collaboratively generate shared soundscapes. Various system designs, ideas and concepts associated with this interaction paradigm are presented and classified by the author.},
  journal = {Leonardo Music Journal},
  author = {Barbosa, Álvaro},
  month = dec,
  year = {2003},
  pages = {53--59},
}

@article{collins_generative_2003,
  title = {Generative music and laptop performance},
  volume = {22},
  issn = {0749-4467},
  url = {https://doi.org/10.1080/0749446032000156919},
  doi = {10.1080/0749446032000156919},
  abstract = {Live computer music is the perfect medium for generative music systems, for non-linear compositional constructions and for interactive manipulation of sound processing. Unfortunately, much of the complexity of these real-time systems is lost on a potential audience, excepting those few connoisseurs who sneak round the back to check the laptop screen. An artist using powerful software like SuperCollider or PD cannot be readily distinguished from someone checking their e-mail whilst DJ-ing with iTunes. Without a culture of understanding of both the laptop performer and current generation graphical and text-programming languages for audio, audiences tend to respond most to often gimmicky controllers, or to the tools they have had more exposure to – the (yawn) superstar DJs and their decks. This article attempts to convey the exciting things that are being explored with algorithmic composition and interactive synthesis techniques in live performance. The reasons for building generative music systems and the forms of control attainable over algorithmic processes are investigated. Direct manual control is set against the use of autonomous software agents. In line with this, four techniques for software control during live performance are introduced, namely presets, previewing, autopilot, and the powerful method of live coding. Finally, audio-visual collaboration is discussed.},
  number = {4},
  urldate = {2020-11-17},
  journal = {Contemporary Music Review},
  author = {Collins, Nick},
  month = dec,
  year = {2003},
  publisher = {Routledge},
  keywords = {algorithmic composition, generative music, laptop music},
  pages = {67--79},
}

@article{zadel_different_2006,
  title = {Different strokes: a prototype software system for laptop performance and improvisation},
  abstract = {This paper presents progress in the design of a new software interface for laptop performance and improvisation. These performances can lack a sense of active creation, as well as a visual connection between the performer’s actions and the audio output. This stems partly from certain patterns in laptop performance in which musicians resort to heavy automation to cope with performing complex compositions. The software presented here attempts to address this by requiring that the user create all of the control sequences on-stage. The user deﬁnes graphical control patterns that are mapped to sample playback. The current prototype resembles a freehand drawing interface where the strokes create looping and cascading animations that generate corresponding audio, ultimately creating music. This style of interface minimizes the use of prepared material and takes advantage of the computer’s unique capabilities.},
  language = {en},
  author = {Zadel, Mark and Scavone, Gary},
  year = {2006},
  pages = {4},
}

@article{j_malloch_generalized_2018,
  title = {Generalized multi-instance control mapping for interactive media systems},
  volume = {25},
  issn = {1941-0166},
  doi = {10.1109/MMUL.2018.112140028},
  abstract = {We articulate a need for the representation of temporal objects reflecting dynamic, short-lived mapping connections instantiated from a template, in tools for designing and using interactive media systems. A list of requirements is compiled from an examination of existing tools, practical use cases, and abstract considerations of node connectivity and information propagation within a graph of connected devices. We validate the concept through implementation in the open source software libmapper, and explore its application by integration with existing controller/synthesizer software and hardware.},
  number = {1},
  journal = {IEEE MultiMedia},
  author = {Joseph Malloch and Steven Sinclair and Marcelo M. Wanderley},
  month = mar,
  year = {2018},
  keywords = {Different Strokes, Influence, MIDI, Media, Multimedia communication, Object recognition, Sensor arrays, Sensor phenomena and characterization, T-Stick, TUIO, abstract considerations, connected devices, controller/synthesizer hardware, controller/synthesizer software, digital musical instrument, existing tools, generalized multiinstance control mapping, gestures, graph theory, information propagation, instances, interactive media, interactive media systems, interactive systems, libmapper, mapping, multi-instance, multimedia, multimedia systems, multitouch interface, node connectivity, open source software libmapper, polyphonic audio synthesis, practical use cases, public domain software, short-lived mapping connections, signals, software libraries, tangible user interface, temporal objects, user interfaces},
  pages = {39--50},
}

@inproceedings{henze_free-hand_2010,
  title = {Free-hand gestures for music playback: deriving gestures with a user-centred process},
  doi = {10.1145/1899475.1899491},
  booktitle = {{MUM} '10: {Proceedings} of the 9th {International} {Conference} on {Mobile} and {Ubiquitous} {Multimedia}},
  author = {Henze, Niels and Löcken, Andreas and Boll, Susanne and Hesselmann, Tobias and Pielot, Martin},
  year = {2010},
  pages = {no. 16, pp. 1--10},
}

@article{airola_augmented_2000,
  title = {Augmented groove: collaborative jamming in augmented reality},
  shorttitle = {Augmented groove},
  url = {https://www.academia.edu/1847254/Augmented_groove_Collaborative_jamming_in_augmented_reality},
  abstract = {Augmented groove: Collaborative jamming in augmented reality},
  language = {en},
  urldate = {2020-11-18},
  journal = {ACM SIGGRAPH 2000 …},
  author = {Airola, Chris},
  year = {2000},
}

@book{bryan-kinns_daisyphone_2004,
  title = {Daisyphone: support for remote music collaboration.},
  shorttitle = {Daisyphone},
  author = {Bryan-Kinns, Nick and Healey, Patrick},
  month = jan,
  year = {2004},
  note = {Pages: 30},
}

@inproceedings{blaine_contexts_2003,
  address = {Montreal, Canada},
  title = {Contexts of collaborative musical experiences},
  url = {https://zenodo.org/record/1176490#.X7VG3tskGCM},
  abstract = {We explore a variety of design criteria applicable to thecreation of collaborative interfaces for musical experience. Themain factor common to the design of most collaborativeinterfaces for novices is that musical control is highlyrestricted, which makes it possible to easily learn andparticipate in the collective experience. Balancing this tradeoff is a key concern for designers, as this happens at theexpense of providing an upward path to virtuosity with theinterface. We attempt to identify design considerationsexemplified by a sampling of recent collaborative devicesprimarily oriented toward novice interplay. It is our intentionto provide a non-technical overview of design issues inherentin configuring multiplayer experiences, particularly for entrylevel players.},
  urldate = {2020-11-18},
  author = {Blaine, Tina and Fels, Sidney S.},
  month = jun,
  year = {2003},
  doi = {10.5281/zenodo.1176490},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
}

@article{green_agility_2011,
  title = {Agility and playfulness: technology and skill in the performance ecosystem},
  volume = {16},
  issn = {1355-7718},
  shorttitle = {Agility and playfulness},
  url = {https://search.proquest.com/docview/890052513/abstract/4103C15EC4BA4309PQ/1},
  abstract = {Whilst it is common in much discourse around contemporary musical practices to emphasise the differences between digital and acoustic ways of making music, Simon Waters' discussion of the Performance Ecosystem as an analytic perspective argues instead for a heightened sense of continuity (Waters 2007). This article lends support to this argument by developing an ecosystemically situated account of our relationships with technology and processes of skill formation. It is argued that this sense of continuity is justified, but that where differences of experiences do arise these are not, as sometimes supposed, an essential characteristic of digital technologies. On the basis that much of our skill formation consists of tacit knowledge, it is suggested that further discussion on how particular circumstances and skills arise would be revealing. Two possible headings for such discussion are suggested in the form of 'Agility' and 'Playfulness'. [PUBLICATION ABSTRACT]},
  language = {English},
  number = {2},
  urldate = {2020-11-17},
  journal = {Organised Sound; Cambridge, Eng.},
  author = {Green, Owen},
  month = aug,
  year = {2011},
  publisher = {Cambridge University Press},
  keywords = {Music, Music Theory/Analysis/Composition, Music--Computer Applications},
  pages = {134--144},
}

@article{noble_taxonomy_nodate,
  title = {A taxonomy of sequencer user-interfaces},
  abstract = {Sequencing tools play a central role in our ability to create computer music. Despite their importance, there has been little structured analysis of how the characteristics of sequencers impact our ability to use them effectively. This paper addresses this through a new taxonomy for classifying sequencing tools. This taxonomy can be used to help us better understand the strengths and weaknesses of current sequencer tools, and suggest novel possibilities for future sequencers.},
  language = {en},
  author = {Noble, James and Biddle, Robert and Duignan, Matthew},
  pages = {4},
}

@inproceedings{carlson_borderlands_2012,
  address = {Ann Arbor, Michigan},
  title = {Borderlands -an audiovisual interface for granular synthesis},
  url = {http://www.nime.org/proceedings/2012/nime2012_152.pdf},
  doi = {10.5281/zenodo.1178229},
  booktitle = {Proceedings of the international conference on new interfaces for musical expression},
  publisher = {University of Michigan},
  author = {Carlson, Chris and Wang, Ge},
  year = {2012},
  keywords = {CCRMA, Granular synthesis, NIME, improvisation, organized sound, painterly interfaces},
}

@article{ames_catalog_1991,
  title = {A catalog of statistical distributions: techniques for transforming random, determinate and chaotic sequences},
  volume = {1},
  issn = {0961-1215},
  shorttitle = {A catalog of statistical distributions},
  doi = {10.2307/1513123},
  abstract = {This article surveys methods for programming computers to realize statistical distributions, strictly isolating distributions per se from random generators so that the same methods may serve random, determinate and chaotic applications. Considerations in choosing appropriate distributions are examined. Numerical methods are provided to realize arbitrary distributions of both discrete and continuous types. Many standard distributions are motivated using probabilistic models. Distributions are illustrated by graphs showing both ideal densities and actual random populations.},
  number = {1},
  urldate = {2020-04-20},
  journal = {Leonardo Music Journal},
  author = {Ames, Charles},
  year = {1991},
  pages = {55--70},
}

@misc{linn_linnstrument_nodate,
  title = {Linnstrument},
  author= {Linn, Roger},
  url = {https://www.rogerlinndesign.com/linnstrument},
  urldate = {2020-11-28},
}

@inproceedings{barbosa_illusio_2013,
  address = {Daejeon, Korea Republic},
  title = {Illusio: a drawing-based digital music instrument},
  abstract = {This paper presents an innovative digital musical instrument, the Illusio, based on an augmented multi-touch interface that combines a traditional multi-touch surface and a device similar to a guitar pedal. Illusio allows users to perform by drawing and by associating the sketches with live loops. These loops are manipulated based on a concept called hierarchical live looping, which extends traditional live looping through the use of a musical tree, in which any music operation applied to a given node affects all its children nodes. Finally, we evaluate the instrument considering the performer and the audience, which are two of the most important stakeholders involved in the use, conception, and perception of a musical device. The results achieved are encouraging and led to useful insights about how to improve instrument features, performance and usability.},
  booktitle = {{NIME} '13 proceedings of the 2013 conference on new interfaces for musical expression},
  author = {Barbosa, Jeronimo and Calegario, Filipe and Teichrieb, Veronica and Ramalho, Geber and Cabral, Giordano},
  year = {2013},
  keywords = {Digital musical instruments, augmented multi-touch, evaluation methodology, hierarchical live looping, interaction techniques},
  pages = {499--502},
}

@misc{nobjsa_petrovic_ribn_2018,
  title = {Ribn},
  url = {https://apps.apple.com/us/app/ribn/id1413777040},
  language = {en-us},
  urldate = {2020-11-20},
  journal = {App Store},
  author = {Nobjsa Petrovic},
  year = {2018},
}

@misc{intellijel_tetrapad_2018,
  title = {Tetrapad},
  url = {https://intellijel.com/shop/eurorack/tetrapad/},
  abstract = {Touch Your Music Nothing is more unique to your music than you. Press and slide your fingers along the four pads to turn your movements into CV and smooth out the rough edges with built in slew. Use it as a keyboard, drum pads, faders, LFOs, voltage memory or more. Add yourself to your music.},
  language = {en-US},
  urldate = {2020-11-20},
  author = {Intellijel},
  year = {2018},
}

@misc{david_cermak_espressifasio_2020,
  title = {espressif/asio},
  url = {https://github.com/espressif/asio},
  abstract = {Asio C++ Library. Contribute to espressif/asio development by creating an account on GitHub.},
  urldate = {2020-05-19},
  publisher = {Espressif Systems},
  author = {David Cermak},
  month = may,
  year = {2020},
}

@misc{peter_kvitek_midirex_2014,
  title = {MidiREX},
  url = {https://midisizer.com/midirex/},
  abstract = {MidiREX is a small but versatile MIDI loop sequencer created for live performance. It is designed to provide basic multi track recording and playback capabilities with minimal distraction to your i…},
  language = {en},
  urldate = {2020-04-18},
  author = {Peter Kvitek},
  month = jan,
  year = {2014},
}

@article{fiebrink_play-along_nodate,
  title = {{PLAY}-{ALONG} {MAPPING} {OF} {MUSICAL} {CONTROLLERS}},
  abstract = {We describe our tool for interactively creating musical controller mappings using a “play-along” paradigm, in which a user pretends to play along with a musical score in real-time using an arbitrary input control modality. As the user “performs,” a supervised machine learning system builds a training dataset from the user’s gestures and the synthesis engine’s current parameters. After one or more training stages, the algorithm learns a mapping from user inputs to synthesis parameters. Control is transferred to the user, who can then control the synthesis in real-time.},
  language = {en},
  author = {Fiebrink, Rebecca and Cook, Perry R and Trueman, Dan},
  pages = {4},
}

@book{richard_barry_mastering_2016,
  title = {Mastering the {FreeRTOS} real time kernel},
  publisher = {Real Time Engineers Ltd.},
  author = {Richard Barry},
  year = {2016},
}

@book{richard_barry_using_2009,
  title = {Using the {FreeRTOS} real time kernel},
  publisher = {http://www.FreeRTOS.org},
  author = {Richard Barry},
  year = {2009},
}

@article{michalevsky_extending_nodate,
  title = {Extending the faust vst architecture with polyphony, portamento and pitch bend},
  abstract = {We introduce the vsti-poly.cpp architecture for the Faust programming language. It provides several features that are important for practical use of Faust-generated VSTi synthesizers. We focus on the VST architecture as one that has been used traditionally and is supported by many popular tools, and add several important features: polyphony, note history and pitch-bend support. These features take Faust-generated VST instruments a step forward in terms of generating plugins that could be used in Digital Audio Workstations (DAW) for real-world music production.},
  language = {en},
  author = {Michalevsky, Yan and Smith, Julius O and Best, Andrew},
  pages = {6},
}

@misc{espressif_systems_esp32_2016,
  title = {{ESP32}},
  url = {https://www.espressif.com/en/products/socs/esp32/overview},
  urldate = {2020-05-05},
  author = {Espressif Systems},
  year = {2016},
}

@inproceedings{chadabe_interactive_1983,
  title = {Interactive composing: an overview},
  booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
  author = {Chadabe, Joel},
  year = {1983},
  pages = {298--306},
}

@inproceedings{calegario_probatio_2020,
  title = {Probatio 1.0: collaborative development of a toolkit for functional {DMI} prototypes},
  copyright = {All rights reserved},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  author = {Calegario, Filipe and Wanderley, Marcelo M. and Tragtenberg, João and Wang, Johnty and Sullivan, John and Meneses, Eduardo and Franco, Ivan and Kirkegaard, Mathias and Bredholt, Mathias and Rohs, Josh},
  year = {2020},
}

@inproceedings{marchini_rethinking_2017,
  address = {Copenhagen, Denmark},
  title = {Rethinking reflexive looper for structured pop music},
  url = {http://www.nime.org/proceedings/2017/nime2017_paper0027.pdf},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  publisher = {Aalborg University Copenhagen},
  author = {Marchini, Marco and Pachet, François and Carré, Benoît},
  year = {2017},
  pages = {139--144},
}

@inproceedings{malloch_libmapper_2013,
  title = {Libmapper (a library for connecting things)},
  url = {https://doi.org/10.1145/2468356.2479617},
  booktitle = {{CHI}},
  author = {Malloch, Joseph and Sinclair, Stephen and Wanderley, Marcelo M.},
  year = {2013},
}

@article{lorrain_panoply_1980,
  title = {A panoply of stochastic 'cannons'},
  volume = {4},
  issn = {0148-9267},
  url = {https://www.jstor.org/stable/3679442},
  doi = {10.2307/3679442},
  number = {1},
  urldate = {2020-04-20},
  journal = {Computer Music Journal},
  author = {Lorrain, Denis},
  year = {1980},
  pages = {53--81},
}

@inproceedings{weinberg_beatbug_2002,
  address = {Dublin, Ireland},
  title = {The beatbug network -a rhythmic system for interdependent group collaboration},
  url = {http://www.nime.org/proceedings/2002/nime2002_186.pdf},
  booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
  author = {Weinberg, Gil and Aimi, Roberto and Jennings, Kevin},
  month = may,
  year = {2002},
  keywords = {Interdependent Musical Networks, group playing, percussive controllers.},
  pages = {186--191},
}

@article{levitin_control_2002,
  title = {Control parameters for musical instruments: a foundation for new mappings of gesture to sound},
  volume = {7},
  issn = {1355-7718},
  url = {https://www.cambridge.org/core/article/control-parameters-for-musical-instruments-a-foundation-for-new-mappings-of-gesture-to-sound/245E50DD691337E6D23DE3F2D805D5B1},
  doi = {10.1017/S135577180200208X},
  abstract = {In this paper we describe a new way of thinking about musical tones, specifically in the context of how features of a sound might be controlled by computer musicians, and how those features might be most appropriately mapped onto musical controllers. Our approach is the consequence of one bias that we should reveal at the outset: we believe that electronically controlled (and this includes computer-controlled)musical instruments need to be emancipated from the keyboard metaphor; although piano-like keyboards are convenient and familiar, they limit the musician's expressiveness (Mathews 1991, Vertegaal and Eaglestone 1996, Paradiso 1997, Levitin and Adams 1998). This is especially true in the domain of computer music,in which timbres can be created that go far beyond the physical constraints of traditional acoustic instruments.},
  number = {2},
  journal = {Organised Sound},
  author = {Levitin, Daniel J. and McAdams, Stephen and Adams, Robert L.},
  year = {2002},
  publisher = {Cambridge University Press},
  pages = {171--189},
}

@inproceedings{garnett_performance_1999,
  title = {Performance factors in control of high-dimensional space},
  booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
  author = {Garnett, Guy E. and Goudeseune, Camille},
  year = {1999},
  pages = {268--271},
}

@book{roads_composing_2015,
  title = {Composing electronic music, a new aesthetic},
  publisher = {Oxford University Press},
  author = {Roads, Curtis},
  year = {2015},
}

@book{hollandsimonNewDirectionsMusic2019,
  title = {New {{Directions}} in {{Music}} and {{Human}}-{{Computer Interaction}}},
  author = {{Holland, Simon} and {Mudd, Tom} and {Wilkie-McKenna}, Katie and McPherson, Andrew and Wanderley, Marcelo M.},
  year = {2019},
  publisher = {{Springer, Cham}},
  isbn = {978-3-319-92068-9},
  note = {\url{https://doi-org.proxy3.library.mcgill.ca/10.1007/978-3-319-92069-6}}
}

@inproceedings{turchetExamplesUseCases2017,
  title = {Examples of {{Use Cases}} with {{Smart Instruments}}},
  booktitle = {Proceedings of the 12th International Audio Mostly Conference on Augmented and Participatory Sound and Music Experiences},
  author = {Turchet, Luca and Benincaso, Michele and Fischione, Carlo},
  year = {2017},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3123514.3123553},
  abstract = {This paper presents some of the possibilities for interaction between performers, audiences, and their smart devices, offered by the novel family of musical instruments, the Smart Instruments. For this purpose, some implemented use cases are described, which involved a preliminary prototype of MIND Music Labs' Sensus Smart Guitar, the first exemplar of Smart Instrument. Sensus consists of a guitar augmented with sensors, actuators, onboard processing, and wireless communication. Some of the novel interactions enabled by Sensus technology are presented, which are based on connectivity of the instrument to smart devices, virtual reality headsets, and the cloud.},
  articleno = {47},
  isbn = {978-1-4503-5373-1},
  keywords = {Internet of Musical Things,Smart Guitar,Smart Instruments,Virtual Reality},
  note = {\url{https://doi.org/10.1145/3123514.3123553}},
  series = {{{AM}} '17}
}

@inproceedings{maplooper_nime,
  title = {MapLooper: Live-looping of distributed gesture-to-sound mappings},
  url = {https://nime.pubpub.org/pub/2pqbusk7/},
  booktitle = {Proceedings of the international conference on new interfaces for musical expression},
  author = {Frisson, Christian and Bredholt, Mathias and Malloch, Joseph and Wanderley, Marcelo M.},
  year = {2021},
}
